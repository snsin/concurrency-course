# Задание 3. Практика: эксперименты с экзекьюторами #

1. Процессор `AMD Ryzen 7 5800U` кол-во ядер 8. Заявлено 2 потока на
   ядро, итого получается 16 потоков, которые в ОС названы логическими процессорами.
2. Имитация блокирующего вызова - `sleep()`
   1. `private ExecutorService executor = Executors.newCachedThreadPool();`
      * Execution time: 15077 мс, загрузка ЦПУ в момент запуска теста около 25%, далее 3-4%
   2. `private ExecutorService executor = Executors.newSingleThreadExecutor();`
      * Execution time: 300 012 мс (таймаут), загрузка ЦПУ - 3-4%. Если убрать таймаут,
        выполнение займет более 1085 000 мс (18 минут).
   3. `private ExecutorService executor = Executors.newFixedThreadPool(n);`
      * n = 8 (кол-во "ядер" / 2) Execution time: 137 152 мс
      * n = 16 (кол-во "ядер") Execution time: 69 307 мс
      * n = 32 (кол-во "ядер" * 2) Execution time: 36 162 мс
      * n = 240 (кол-во вызовов `reportService.getReport()` в тесте) Execution time: 15 096 мс
      * n = 48 ( кол-во задач, которые сабмитятся в executor теста) Execution time: 24 117 мс
      * n = 96 (кол-во задач, которые сабмитятся в ReportServiceExecutors при старте теста: 
        16 "ядер" * 3 = 48 кол-во потоков в пуле теста, 48 * 2 задачи: `() -> getItems()`
        `+` `() -> getActiveCustomers()`), т.е. для данного кода это число одновременно 
        заблокированных задач. Execution time: 15 072 мс
   4. `private ExecutorService executor = Executors.newWorkStealingPool(n);`
      * n = 16 Execution time: 73 863 мс
      * n = 96 Execution time: 16 553 мс
      * n = 200 Execution time: 15 106 мс
3. Имитация вычислительной нагрузки - `compute()`
   1. ` private ExecutorService executor = Executors.newCachedThreadPool();`
      * Execution time: 44 108 мс нагрузка на все ядра процессора 100% 
   2. `private ExecutorService executor = Executors.newSingleThreadExecutor();`
      * Execution time: 187 795 мс нагрузка - пила (трапеция 0 - 100% - 0) на 2 ядра процессора,
        возможно одно ядро на задачу, другое на GC
   3. `private ExecutorService executor = Executors.newFixedThreadPool(n);`
      * n = 6 Execution time: 45 860 мс Загрузка процессора 20-100% 12 ядер, 20-30% 4 ядра
      * n = 8 Execution time: 42 037 мс Загрузка процессора 50-100% все ядра
      * n = 10 Execution time: 42 418 мс Загрузка процессора 60-100% все ядра
      * n = 12 Execution time: 42 827 мс Загрузка процессора 70-100% все ядра
      * n = 15 Execution time: 43 378 мс Загрузка процессора 100% все ядра
      * n = 16 Execution time: 44 317 мс Загрузка процессора 100% все ядра
      * n = 32 Execution time: 46 046 мс Загрузка процессора 100% все ядра
   4. `private ExecutorService executor = Executors.newWorkStealingPool(8);`
      * n = 8 Execution time: 46 080 мс загрузка процессора 50-100% все ядра
      * n = 16 Execution time: 43 887 мс Загрузка процессора 100% все ядра
      * n = 32 Execution time: 47 812 мс Загрузка процессора 100% все ядра
4. Выводы: настройки TreadPoolExecutor для получения максимального быстродействия системы зависит от
   характера нагрузки на приложение (систему).
   1. Если приложение в основном выполняет блокирующие вызовы (io-операции, обращения к БД,
      обмен данными по сети), то для получения максимального быстродействия, т.е. максимального rps
      необходимо увеличивать кол-во потоков в пуле до определенного предела. Максимальную
      производительность можно получить, при количестве потоков, равных кол-ву одновременно 
      заблокированных задач.

      Для умеренных и умеренных эпизодических нагрузок на систему может подойти CachedThreadPool, 
      при условии, что блокирующие задачи не блокируются слишком надолго.
   2. Если приложение в основном выполняет расчеты (например, цифровую обработку сигналов),
      то для получения максимального быстродействия не требуется потоков больше чем кол-во ядер
      процессора. В конкретном тесте выяснилось, что наилучшие результаты достигаются при
      количестве потоков равном половине количества ядер. Вероятно такой результат связан с тем,
      что при кол-ве потоков, равному половине количества ядер jvm удается оптимально распределить
      нагрузку между сборщиком мусора, jit-компилятором и выполняемой задачей. При увеличении 
      количества потоков в ThreadPool больше вычислительных ресурсов идет на выполнение задачи
      и меньше ресурсов остается на служебные потоки, в том числе, на выполннение задач сборщиком
      мусора.